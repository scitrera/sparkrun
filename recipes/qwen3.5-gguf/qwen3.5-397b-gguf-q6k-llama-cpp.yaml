model: unsloth/Qwen3.5-397B-A17B-GGUF:Q6_K
runtime: llama-cpp
min_nodes: 4
container: scitrera/dgx-spark-llama-cpp:b8094-cu131

metadata:
  description: Qwen3.5 397B (GGUF, unsloth quant, Q6_K)
  maintainer: scitrera.ai <open-source-team@scitrera.com>
  model_params: 397B
  model_dtype: q6_k

defaults:  # TODO: --threads,
  port: 8000
  host: 0.0.0.0
  n_gpu_layers: 99
  ctx_size: 262144
  split_mode: layer  # TODO: test performance of row

command: |
  llama-server \
      -hf {model} \
      --host {host} \
      --port {port} \
      --n-gpu-layers {n_gpu_layers} \
      --ctx-size {ctx_size} \
      --flash-attn on \
      --jinja \
      --split-mode {split_mode} \
      --no-webui \
      --no-mmap