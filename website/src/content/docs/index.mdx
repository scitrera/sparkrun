---
title: sparkrun
description: One command to rule them all — launch, manage, and stop LLM inference workloads on NVIDIA DGX Spark systems.
template: splash
hero:
  tagline: Launch, manage, and stop LLM inference workloads on one or more NVIDIA DGX Spark systems — no Slurm, no Kubernetes, no fuss.
  actions:
    - text: Get Started
      link: /getting-started/installation/
      icon: right-arrow
      variant: primary
    - text: View on GitHub
      link: https://github.com/scitrera/sparkrun
      icon: external
      variant: minimal
---

import HeroVideo from '../../components/landing/HeroVideo.tsx';
import InstallCommand from '../../components/landing/InstallCommand.tsx';
import FeatureCards from '../../components/landing/FeatureCards.tsx';
import QuickStart from '../../components/landing/QuickStart.tsx';
import Footer from '../../components/landing/Footer.tsx';

<HeroVideo />

<InstallCommand client:load />

<FeatureCards />

<QuickStart />

<Footer />
