model: MiniMaxAI/MiniMax-M2.5
runtime: sglang
min_nodes: 4
container: scitrera/dgx-spark-sglang:0.5.8-t5

metadata:
  description: MiniMax-M2.5 (upstream, no quant) SGLang Cluster (4 nodes+)
  maintainer: scitrera.ai <open-source-team@scitrera.com>
  model_params: 229B
  model_dtype: fp8

defaults:
  port: 8000
  host: 0.0.0.0
  tensor_parallel: 4
  gpu_memory_utilization: 0.8
  max_model_len: 196608
  served_model_name: minimax-m2.5
  attention_backend: triton
  tool_call_parser: minimax-m2
  reasoning_parser: minimax-append-think

command: |
  python3 -m sglang.launch_server \
      --model-path {model} \
      --served-model-name {served_model_name} \
      --context-length {max_model_len} \
      --mem-fraction-static {gpu_memory_utilization} \
      --tp-size {tensor_parallel} \
      --host {host} \
      --port {port} \
      --attention-backend {attention_backend} \
      --tool-call-parser {tool_call_parser} \
      --reasoning-parser {reasoning_parser} \
      --trust-remote-code
